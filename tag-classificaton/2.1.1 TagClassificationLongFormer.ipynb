{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47092fb4-394e-4de1-a37b-b91ef3ee02d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -q transformers[torch] accelerate\n",
    "# !pip3 install -q wandb\n",
    "# !pip3 install -q openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52084bd8-b7d8-46c9-a4ac-b9befabf853d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd \n",
    "import os \n",
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ef8f25-49ac-4afa-adb4-5809eb7d949c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3d711a1-0e5b-4d98-b300-244eb13bbaef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import LongformerTokenizer, LongformerForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import classification_report, precision_recall_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce7a96f4-3262-4f51-b717-9932be392b64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip3 uninstall -q wandb -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65249068-80c2-4bb8-b11f-5352cb22d0ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9ce1d0b-462a-49b2-bf14-99dc9232d3d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"4de6103347df6561e7258cdef0ef60bbc1233695\", relogin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8c6a2e3-d432-4a39-b787-78722225a649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_DIRECTORY = \"./trained_model/v1-longformer\"\n",
    "DATA_DIRECTORY = \"./data/dataset/v7/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3486ece-acae-43bf-abfb-8c82bc4fec99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=4096):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt',\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(labels, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87883537-8e10-4469-8506-1a904cd92466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_json(os.path.join(DATA_DIRECTORY, \"train.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e2130c1-6ffa-4b1a-8a06-0ad1e75d63ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3085, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b82b647-f4ba-4282-980f-070a0855d2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138,)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.filename.unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8f5fd7d-4a76-4277-8bc4-c3dcb2335d85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = train_df['section_content'].values\n",
    "labels_text = train_df['tags'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46f22f3c-5405-4dbb-a34e-894c7c55d54b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd6525f5-779c-448c-a563-71f7744afc1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: './trained_model/v1-longformer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_DIRECTORY\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: './trained_model/v1-longformer'"
     ]
    }
   ],
   "source": [
    "os.makedirs(MODEL_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c63686c3-265f-443e-9d5b-6de0761573d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(MODEL_DIRECTORY, \"tag.le\"), 'wb') as file: \n",
    "    pickle.dump(label_encoder, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c24ec504-b16a-44ab-be65-710d82a51216",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels 23\n"
     ]
    }
   ],
   "source": [
    "num_labels = train_df.tags.unique().shape[0]\n",
    "print(\"Number of labels\", num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c5f6c7-39f5-437c-b9d7-f27320c036ad",
   "metadata": {},
   "source": [
    "## Calculate Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28a404dd-1cf2-4015-807e-473dd5611f20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "397272fd-3000-4e12-9db7-94a38e83040e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights:  {0: 2.2355072463768115, 1: 3.8322981366459627, 2: 1.889161053276179, 3: 3.945012787723785, 4: 2.273397199705232, 5: 1.166351606805293, 6: 2.1633941093969145, 7: 1.6160293347302253, 8: 2.6826086956521737, 9: 3.945012787723785, 10: 1.8125734430082256, 11: 2.0635451505016724, 12: 2.353165522501907, 13: 0.07037273598248095, 14: 7.451690821256038, 15: 3.8322981366459627, 16: 2.0635451505016724, 17: 2.9158790170132325, 18: 1.8125734430082256, 19: 7.059496567505721, 20: 3.945012787723785, 21: 3.6251468860164513, 22: 2.57943143812709}\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "print(\"Class Weights: \", class_weights_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdd9ba53-ddc7-4a88-ab17-0458337a39b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_weight_tensor = torch.tensor(class_weights, dtype=torch.float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9724721d-a2eb-4fe3-b201-f6ded2967bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_weighted_loss(model, inputs, return_outputs=False): \n",
    "    labels = inputs.get(\"labels\") \n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.get(\"logits\")\n",
    "    loss_fct = torch.nn.CrossEntropyLoss(weight=class_weight_tensor.to(logits.device))\n",
    "    loss = loss_fct(logits, labels) \n",
    "    return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f96031-b9da-4c2a-8e8d-5840325cd917",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cd9bf7a-ffd6-4d53-8f03-c54f23b6e18d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cf9cbe-89cc-492b-a17d-ef09b4125c0c",
   "metadata": {},
   "source": [
    "## Compute Metrics callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bf0a4f0-0423-4023-ac89-b8c11ef65cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e27fa414-69a1-4ee4-84d9-cf20990625c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions, )\n",
    "    precision = precision_score(labels, predictions, average='macro')\n",
    "    recall = recall_score(labels, predictions, average='macro')\n",
    "    f1 = f1_score(labels, predictions, average='macro')\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60d4033d-0c64-4e80-ba0a-fb49aee49d02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./trained_model/v1-longformer'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c4f29c1-cb9e-47d0-b7d3-619b4fef4b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights.to(logits.device))\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65207a5d-4e02-4b34-9cf3-e3fa73a93994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = TextDataset(texts, labels, tokenizer, max_length=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "097f837f-7cf2-4321-9da2-ec8d4fc62ba1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./trained_model/v1-longformer\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bfeb337-f465-484a-ad14-4522a4dbc0cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-base-4096', num_labels=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2427982d-681b-487c-aa59-e818d637cf73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.join(MODEL_DIRECTORY, './results'),\n",
    "    run_name=f\"{Path(MODEL_DIRECTORY).name}\",\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=os.path.join(MODEL_DIRECTORY, './logs'),\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-5,\n",
    "    eval_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=dataset, \n",
    "    compute_metrics=compute_metrics, \n",
    "    class_weights=class_weight_tensor\n",
    ")\n",
    "\n",
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ca020a-9dd4-4d0d-9272-928665e56495",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manurag-credcore\u001b[0m (\u001b[33mcredcore\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/wandb/run-20240824_150140-q0j3fi3e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/credcore/huggingface/runs/q0j3fi3e' target=\"_blank\">v1-longformer</a></strong> to <a href='https://wandb.ai/credcore/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/credcore/huggingface' target=\"_blank\">https://wandb.ai/credcore/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/credcore/huggingface/runs/q0j3fi3e' target=\"_blank\">https://wandb.ai/credcore/huggingface/runs/q0j3fi3e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing global attention on CLS token...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='445' max='77150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  445/77150 11:21 < 32:46:25, 0.65 it/s, Epoch 0.29/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4ca592-10ac-4df1-a926-6344f93b5239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eval_results = trainer.evaluate()\n",
    "# print(f\"Evaluation results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e6351b-6ac4-457a-8f70-f30cfa931f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model and tokenizer to disk\n",
    "model.save_pretrained(MODEL_DIRECTORY)\n",
    "tokenizer.save_pretrained(MODEL_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cdfca5-ae47-43ad-aea0-50aa126fc3a4",
   "metadata": {},
   "source": [
    "# Load Model For Inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e93f17-03d0-4590-8139-854601ed90cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd \n",
    "import os \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ace0352-1738-4ad3-b0d8-5129f6113856",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40556c6a-45c9-402c-95d0-4b171e543866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import classification_report, precision_recall_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16729842-6cbe-494a-8d09-ab25fb29c3c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(MODEL_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cbd56b-f7b2-4f45-9fcc-690bee000fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(MODEL_DIRECTORY)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cf562f-3454-437e-9f9e-be23ad3839ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_json(os.path.join(DATA_DIRECTORY, \"test.json\"))\n",
    "test_df = test_df.drop_duplicates(\"section_content\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6df379-76a6-477e-99d1-3e0d556197cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(MODEL_DIRECTORY, \"tag.le\"), 'rb') as file: \n",
    "    label_encoder = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0e5cb4-fa72-4b18-8135-bf439755836f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_texts = test_df['section_content'].values\n",
    "test_labels = test_df['tags'].values\n",
    "test_labels = label_encoder.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af939265-abf3-408c-8b2b-1251be41c691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb0dfa9-a95e-4d6f-be3f-c947b1e97e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt',\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(labels, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42d421c-2740-4f61-acfb-755046c2d734",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = TextDataset(test_texts, test_labels, tokenizer, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c83f58-de69-4597-8cf1-3f6f81a78a33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_args = TrainingArguments(\n",
    "    output_dir='./results',  \n",
    "    per_device_eval_batch_size=32, \n",
    "    dataloader_drop_last=False,  \n",
    "    no_cuda=False if torch.cuda.is_available() else True, \n",
    "    seed=42,  \n",
    "    report_to=\"none\" # Disable wandb reporting. \n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args = inference_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b594fedc-129a-4cfc-a175-141abe203221",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c540d157-2208-4b7a-85cf-161b46ce089a",
   "metadata": {},
   "source": [
    "## Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a6c0b-c6e8-4280-9127-1d191245ae3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = trainer.predict(dataset)\n",
    "\n",
    "# Extract the logits and convert to predicted labels\n",
    "logits = predictions.predictions\n",
    "predicted_labels = np.argmax(logits, axis=-1)\n",
    "\n",
    "# Convert numeric labels back to original text labels for comparison\n",
    "predicted_labels_text = label_encoder.inverse_transform(predicted_labels)\n",
    "true_labels_text = label_encoder.inverse_transform(labels)\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(true_labels_text, predicted_labels_text, target_names=label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce71398d-9a20-4ec3-b036-8a16e595122e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1d2105-0d86-442d-8144-2838906f03b9",
   "metadata": {},
   "source": [
    "## Test Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d8d2b-24dd-465c-86a2-3e547664feba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# Extract the logits and convert to predicted labels\n",
    "logits = predictions.predictions\n",
    "predicted_labels = np.argmax(logits, axis=-1)\n",
    "\n",
    "# Convert numeric labels back to original text labels for comparison\n",
    "predicted_labels_text = label_encoder.inverse_transform(predicted_labels)\n",
    "true_labels_text = label_encoder.inverse_transform(test_labels)\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(true_labels_text, predicted_labels_text, target_names=label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c0bc7-ddd2-41d8-8113-1773e63995b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a22185-999d-4127-9539-2ede8d193168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df['Predicted_Tag'] = predicted_labels_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3cad14-e9e0-4ada-8dd6-0a75c1478e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = test_df.rename(columns = {\"tag\": \"Original_Tag\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3755ef69-2dae-4144-99ae-12203f2520a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94fd4e1-d5e5-44f5-a1c8-100fbb4f4993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.to_excel(\"./data/output/predictions_v9_small.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119349fc-de64-4e64-a3fa-1b664c74fc6e",
   "metadata": {},
   "source": [
    "# Train using K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b391734-d185-44c6-af45-82722ef1f551",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import json \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8daeb8fb-f4c6-44c4-8704-8f8baad8de8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k=5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "202810f3-3515-45f6-b44c-61efecd40186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_files = train_df[train_df.filename.str.contains(\"synth\") == False].filename.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee709dad-0779-4c1e-a9d2-a3f93c560a31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2341, 9) (23,)\n",
      "(573, 9) (23,)\n",
      "(2358, 9) (23,)\n",
      "(556, 9) (21,)\n",
      "(2204, 9) (23,)\n",
      "(710, 9) (23,)\n",
      "(2372, 9) (23,)\n",
      "(542, 9) (23,)\n",
      "(2381, 9) (23,)\n",
      "(533, 9) (23,)\n"
     ]
    }
   ],
   "source": [
    "splits = list(kf.split(unique_files))\n",
    "for fold, (train_file_index, val_file_index)  in enumerate(splits):\n",
    "    train_file_names = set(unique_files[train_file_index])\n",
    "    val_file_names = set(unique_files[val_file_index])\n",
    "    \n",
    "    train = train_df[train_df.filename.isin(train_file_names)]\n",
    "    val  = train_df[train_df.filename.isin(val_file_names)]\n",
    "    print(train.shape, train.tags.unique().shape)\n",
    "    print(val.shape, val.tags.unique().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7fb081-618b-4fb8-a0fb-1730a928ddc5",
   "metadata": {},
   "source": [
    "# Split by files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84a8698e-dc3f-45b3-9da3-b6149e67830b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_labels = train_df.tags.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0784675a-61f5-46f6-82a7-e58b2230b4de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fold_accuracies = [] \n",
    "for fold, (train_file_index, val_file_index)  in enumerate(splits):\n",
    "    \n",
    "    train_file_names = set(unique_files[train_file_index])\n",
    "    val_file_names = set(unique_files[val_file_index])\n",
    "    \n",
    "    train = train_df[train_df.filename.isin(train_file_names)]\n",
    "    val  = train_df[train_df.filename.isin(val_file_names)]\n",
    "    \n",
    "    val_labels = label_encoder.transform(val['tags'].values)\n",
    "    train_labels = label_encoder.transform(train['tags'].values)\n",
    "    \n",
    "    train_dataset = TextDataset(train['section_content'].values, train_labels ,  tokenizer, max_length=512)\n",
    "    val_dataset = TextDataset(val['section_content'].values, val_labels,  tokenizer, max_length=512)\n",
    "    \n",
    "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)\n",
    "    \n",
    "    run_name = f\"{Path(MODEL_DIRECTORY).name}_fold_{fold+1}\"    \n",
    "    print(\"Starting \", run_name)\n",
    "    wandb.init(project=\"huggingface\", name=run_name)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=os.path.join(MODEL_DIRECTORY, f'./results_fold_{fold+1}'),\n",
    "        run_name=run_name,\n",
    "        num_train_epochs=30,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=os.path.join(MODEL_DIRECTORY, f'./logs_fold_{fold+1}'),\n",
    "        logging_steps=10,\n",
    "        learning_rate=2e-5,\n",
    "        eval_strategy=\"epoch\", \n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='recall'\n",
    "\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset, \n",
    "        compute_metrics=compute_metrics, \n",
    "        class_weights=class_weight_tensor, \n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    # Train the model\n",
    "    # Make predictions on the test set\n",
    "    predictions = trainer.predict(val_dataset)\n",
    "\n",
    "    # Extract the logits and convert to predicted labels\n",
    "    logits = predictions.predictions\n",
    "    predicted_labels = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Convert numeric labels back to original text labels for comparison\n",
    "    predicted_labels_text = label_encoder.inverse_transform(predicted_labels)\n",
    "    true_labels_text = label_encoder.inverse_transform(val_labels)\n",
    "    \n",
    "    val['predicted_tags'] = predicted_labels_text\n",
    "    val.to_json(f\"./data/output/val_{Path(MODEL_DIRECTORY).name}_fold_{fold+1}.json\", orient=\"records\")\n",
    "    # Generate a classification report\n",
    "    report = classification_report(true_labels_text, predicted_labels_text, target_names=label_encoder.classes_, labels=unique_labels, output_dict=True)\n",
    "    with open(f\"./data/output/tag_classification_fold_{fold+1}_report.json\", \"w\") as file: \n",
    "        json.dump(report, file)\n",
    "        \n",
    "    print(report)\n",
    "        \n",
    "    \n",
    "    print(\"Generating Evaluation results\")\n",
    "    eval_result = trainer.evaluate()\n",
    "    # Save accuracy for this fold\n",
    "    fold_accuracies.append((report, eval_result['eval_accuracy']))\n",
    "    del model \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73454a1-425d-44ea-abc7-f1ff665cec7c",
   "metadata": {},
   "source": [
    "# Split by rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a653eb-6f89-4f09-98bc-81affa7bf984",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Starting  v11-small_fold_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manurag-credcore\u001b[0m (\u001b[33mcredcore\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/wandb/run-20240822_184907-zinhnxg7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/credcore/huggingface/runs/zinhnxg7' target=\"_blank\">v11-small_fold_1</a></strong> to <a href='https://wandb.ai/credcore/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/credcore/huggingface' target=\"_blank\">https://wandb.ai/credcore/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/credcore/huggingface/runs/zinhnxg7' target=\"_blank\">https://wandb.ai/credcore/huggingface/runs/zinhnxg7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4650' max='4650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4650/4650 41:40, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.077200</td>\n",
       "      <td>2.362797</td>\n",
       "      <td>0.473258</td>\n",
       "      <td>0.469511</td>\n",
       "      <td>0.838682</td>\n",
       "      <td>0.549513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.816200</td>\n",
       "      <td>1.399544</td>\n",
       "      <td>0.708266</td>\n",
       "      <td>0.592619</td>\n",
       "      <td>0.890267</td>\n",
       "      <td>0.688403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.319300</td>\n",
       "      <td>0.696363</td>\n",
       "      <td>0.846029</td>\n",
       "      <td>0.761781</td>\n",
       "      <td>0.939490</td>\n",
       "      <td>0.823779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.176900</td>\n",
       "      <td>0.331885</td>\n",
       "      <td>0.910859</td>\n",
       "      <td>0.837361</td>\n",
       "      <td>0.915628</td>\n",
       "      <td>0.867350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.349098</td>\n",
       "      <td>0.912480</td>\n",
       "      <td>0.823768</td>\n",
       "      <td>0.952591</td>\n",
       "      <td>0.876586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.320608</td>\n",
       "      <td>0.914100</td>\n",
       "      <td>0.840754</td>\n",
       "      <td>0.968206</td>\n",
       "      <td>0.893099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.250025</td>\n",
       "      <td>0.935170</td>\n",
       "      <td>0.878280</td>\n",
       "      <td>0.932558</td>\n",
       "      <td>0.900807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.161200</td>\n",
       "      <td>0.273920</td>\n",
       "      <td>0.941653</td>\n",
       "      <td>0.887081</td>\n",
       "      <td>0.953572</td>\n",
       "      <td>0.917525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.318282</td>\n",
       "      <td>0.936791</td>\n",
       "      <td>0.873630</td>\n",
       "      <td>0.955300</td>\n",
       "      <td>0.908921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.101800</td>\n",
       "      <td>0.296882</td>\n",
       "      <td>0.940032</td>\n",
       "      <td>0.880521</td>\n",
       "      <td>0.958841</td>\n",
       "      <td>0.915121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>0.288699</td>\n",
       "      <td>0.941653</td>\n",
       "      <td>0.899325</td>\n",
       "      <td>0.950204</td>\n",
       "      <td>0.921301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.303381</td>\n",
       "      <td>0.944895</td>\n",
       "      <td>0.914692</td>\n",
       "      <td>0.948656</td>\n",
       "      <td>0.928239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.299814</td>\n",
       "      <td>0.948136</td>\n",
       "      <td>0.911873</td>\n",
       "      <td>0.958687</td>\n",
       "      <td>0.932741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.313092</td>\n",
       "      <td>0.940032</td>\n",
       "      <td>0.885876</td>\n",
       "      <td>0.963402</td>\n",
       "      <td>0.919450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.074700</td>\n",
       "      <td>0.323602</td>\n",
       "      <td>0.938412</td>\n",
       "      <td>0.883008</td>\n",
       "      <td>0.970393</td>\n",
       "      <td>0.921944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.349500</td>\n",
       "      <td>0.303009</td>\n",
       "      <td>0.948136</td>\n",
       "      <td>0.909948</td>\n",
       "      <td>0.957679</td>\n",
       "      <td>0.931691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.364227</td>\n",
       "      <td>0.936791</td>\n",
       "      <td>0.879116</td>\n",
       "      <td>0.964710</td>\n",
       "      <td>0.917534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.349967</td>\n",
       "      <td>0.938412</td>\n",
       "      <td>0.889245</td>\n",
       "      <td>0.958003</td>\n",
       "      <td>0.919684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.323886</td>\n",
       "      <td>0.943274</td>\n",
       "      <td>0.906632</td>\n",
       "      <td>0.952051</td>\n",
       "      <td>0.926719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.312587</td>\n",
       "      <td>0.946515</td>\n",
       "      <td>0.912798</td>\n",
       "      <td>0.952280</td>\n",
       "      <td>0.930323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.334181</td>\n",
       "      <td>0.946515</td>\n",
       "      <td>0.907617</td>\n",
       "      <td>0.958573</td>\n",
       "      <td>0.930801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.324378</td>\n",
       "      <td>0.949757</td>\n",
       "      <td>0.922737</td>\n",
       "      <td>0.946411</td>\n",
       "      <td>0.932367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.357920</td>\n",
       "      <td>0.940032</td>\n",
       "      <td>0.893742</td>\n",
       "      <td>0.958117</td>\n",
       "      <td>0.922404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.358996</td>\n",
       "      <td>0.941653</td>\n",
       "      <td>0.891482</td>\n",
       "      <td>0.961015</td>\n",
       "      <td>0.922839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.350882</td>\n",
       "      <td>0.944895</td>\n",
       "      <td>0.907076</td>\n",
       "      <td>0.955675</td>\n",
       "      <td>0.929264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.338502</td>\n",
       "      <td>0.949757</td>\n",
       "      <td>0.916143</td>\n",
       "      <td>0.956017</td>\n",
       "      <td>0.933886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.342944</td>\n",
       "      <td>0.948136</td>\n",
       "      <td>0.913242</td>\n",
       "      <td>0.955903</td>\n",
       "      <td>0.932426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.353471</td>\n",
       "      <td>0.944895</td>\n",
       "      <td>0.907076</td>\n",
       "      <td>0.955675</td>\n",
       "      <td>0.929264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>0.348978</td>\n",
       "      <td>0.948136</td>\n",
       "      <td>0.913242</td>\n",
       "      <td>0.955903</td>\n",
       "      <td>0.932426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.349920</td>\n",
       "      <td>0.948136</td>\n",
       "      <td>0.913242</td>\n",
       "      <td>0.955903</td>\n",
       "      <td>0.932426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/1994849025.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val['predicted_tags'] = predicted_labels_text\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Additional Liens': {'precision': 0.9166666666666666, 'recall': 0.9166666666666666, 'f1-score': 0.9166666666666666, 'support': 12}, 'Asset Disposition': {'precision': 0.875, 'recall': 1.0, 'f1-score': 0.9333333333333333, 'support': 7}, 'Compliance Certificate': {'precision': 0.875, 'recall': 0.9333333333333333, 'f1-score': 0.9032258064516129, 'support': 15}, 'Consequences of Default': {'precision': 0.8571428571428571, 'recall': 0.8571428571428571, 'f1-score': 0.8571428571428571, 'support': 7}, 'Event of Default': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 11}, 'Facilities / Instrument': {'precision': 0.875, 'recall': 0.9130434782608695, 'f1-score': 0.8936170212765957, 'support': 23}, 'Financial Covenant': {'precision': 0.9230769230769231, 'recall': 1.0, 'f1-score': 0.9600000000000001, 'support': 12}, 'Financial Statements': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 16}, 'Governing Laws': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 10}, 'Incremental Facilities': {'precision': 0.6666666666666666, 'recall': 0.8571428571428571, 'f1-score': 0.75, 'support': 7}, 'Interest Rate': {'precision': 0.7894736842105263, 'recall': 1.0, 'f1-score': 0.8823529411764706, 'support': 15}, 'Loan Repayment': {'precision': 0.75, 'recall': 0.9230769230769231, 'f1-score': 0.8275862068965517, 'support': 13}, 'Mandatory Prepayments / Redemption': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 12}, 'NA': {'precision': 0.9831460674157303, 'recall': 0.9186351706036745, 'f1-score': 0.9497964721845318, 'support': 381}, 'Optional Prepayment / Redemption': {'precision': 0.8, 'recall': 1.0, 'f1-score': 0.888888888888889, 'support': 4}, 'Permitted Indebtedness': {'precision': 0.875, 'recall': 1.0, 'f1-score': 0.9333333333333333, 'support': 7}, 'Premium and Fees': {'precision': 0.9285714285714286, 'recall': 1.0, 'f1-score': 0.962962962962963, 'support': 13}, 'Prepayment': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 9}, 'Reporting Requirements': {'precision': 0.75, 'recall': 1.0, 'f1-score': 0.8571428571428571, 'support': 15}, 'Restricted Investments': {'precision': 0.75, 'recall': 1.0, 'f1-score': 0.8571428571428571, 'support': 3}, 'Restricted Payments': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 7}, 'Transactions with Affiliates': {'precision': 0.7777777777777778, 'recall': 1.0, 'f1-score': 0.8750000000000001, 'support': 7}, 'Waterfall of Proceeds': {'precision': 0.9166666666666666, 'recall': 1.0, 'f1-score': 0.9565217391304348, 'support': 11}, 'accuracy': 0.9384116693679092, 'macro avg': {'precision': 0.8830082060084888, 'recall': 0.9703930994011819, 'f1-score': 0.921944084509998, 'support': 617}, 'weighted avg': {'precision': 0.9460511394511301, 'recall': 0.9384116693679092, 'f1-score': 0.9399578615810239, 'support': 617}}\n",
      "Generating Evaluation results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting  v11-small_fold_2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='85' max='4650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  85/4650 00:34 < 31:43, 2.40 it/s, Epoch 0.54/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fold_accuracies = [] \n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_df, train_df['tags'].values)):\n",
    "    print(f\"Fold {fold + 1}/{k}\")\n",
    "    train = train_df.iloc[train_index]\n",
    "    val = train_df.iloc[val_index]\n",
    "    \n",
    "    val_labels = label_encoder.transform(val['tags'].values)\n",
    "    train_labels = label_encoder.transform(train['tags'].values)\n",
    "    \n",
    "    train_dataset = TextDataset(train['section_content'].values, train_labels ,  tokenizer, max_length=512)\n",
    "    val_dataset = TextDataset(val['section_content'].values, val_labels,  tokenizer, max_length=512)\n",
    "    \n",
    "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)\n",
    "    \n",
    "    run_name = f\"{Path(MODEL_DIRECTORY).name}_fold_{fold+1}\"\n",
    "    wandb.run_name = run_name\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"Starting \", run_name)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=os.path.join(MODEL_DIRECTORY, f'./results_fold_{fold+1}'),\n",
    "        run_name=run_name,\n",
    "        num_train_epochs=30,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=os.path.join(MODEL_DIRECTORY, f'./logs_fold_{fold+1}'),\n",
    "        logging_steps=10,\n",
    "        learning_rate=2e-5,\n",
    "        eval_strategy=\"epoch\", \n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='recall'\n",
    "\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset, \n",
    "        compute_metrics=compute_metrics, \n",
    "        class_weights=class_weight_tensor, \n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    # Train the model\n",
    "    # Make predictions on the test set\n",
    "    predictions = trainer.predict(val_dataset)\n",
    "\n",
    "    # Extract the logits and convert to predicted labels\n",
    "    logits = predictions.predictions\n",
    "    predicted_labels = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Convert numeric labels back to original text labels for comparison\n",
    "    predicted_labels_text = label_encoder.inverse_transform(predicted_labels)\n",
    "    true_labels_text = label_encoder.inverse_transform(val_labels)\n",
    "    \n",
    "    val['predicted_tags'] = predicted_labels_text\n",
    "    val.to_json(f\"./data/output/val_{Path(MODEL_DIRECTORY).name}_fold_{fold+1}.json\", orient=\"records\")\n",
    "    # Generate a classification report\n",
    "    report = classification_report(true_labels_text, predicted_labels_text, target_names=label_encoder.classes_, output_dict=True)\n",
    "    with open(f\"./data/output/tag_classification_fold_{fold+1}_report.json\", \"w\") as file: \n",
    "        json.dump(report, file)\n",
    "        \n",
    "    print(report)\n",
    "        \n",
    "    \n",
    "    print(\"Generating Evaluation results\")\n",
    "    eval_result = trainer.evaluate()\n",
    "    # Save accuracy for this fold\n",
    "    fold_accuracies.append((report, eval_result['eval_accuracy']))\n",
    "    del model \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ee6be09-b299-4839-9b6e-73810d5b705e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb459ab-3ebf-45cd-8c5c-5a14ed89bef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "04f934d2-11b3-4cb2-9596-5d1d903fe060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fold_data = []\n",
    "for x in fold_accuracies[1:]:\n",
    "    for key, value in x[0].items(): \n",
    "        if type(value) != dict:\n",
    "            continue\n",
    "        fold_data.append({\n",
    "            \"tag\": key, \n",
    "            \"precision\": value['precision'], \n",
    "            'recall' : value['recall'], \n",
    "            'f1-score': value['f1-score'], \n",
    "            'support': value['support']\n",
    "        })\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dff9d4e7-24b1-4bdf-996f-57d50c01c59d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9529983792544571\n",
      "0.946515397082658\n",
      "0.9124797406807131\n",
      "0.9562398703403565\n",
      "0.9141004862236629\n",
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n"
     ]
    }
   ],
   "source": [
    "for i in fold_accuracies: \n",
    "    print(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "81111c87-50db-492f-ae14-a24e5ba4f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_df = pd.DataFrame(fold_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fbf235cc-15ca-45db-84df-5a5ade56dd34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score  support\n",
      "tag                                                                       \n",
      "Additional Liens                     0.909091  1.000000  0.952381     50.0\n",
      "Asset Disposition                    0.966667  1.000000  0.983051     29.0\n",
      "Compliance Certificate               0.920635  1.000000  0.958678     58.0\n",
      "Consequences of Default              0.935484  1.000000  0.966667     29.0\n",
      "Event of Default                     0.962963  1.000000  0.981132     52.0\n",
      "Facilities / Instrument              0.938776  1.000000  0.968421     92.0\n",
      "Financial Covenant                   0.961538  1.000000  0.980392     50.0\n",
      "Financial Statements                 0.971014  1.000000  0.985294     67.0\n",
      "Governing Laws                       0.911111  1.000000  0.953488     41.0\n",
      "Incremental Facilities               0.781250  1.000000  0.877193     25.0\n",
      "Interest Rate                        0.919355  1.000000  0.957983     57.0\n",
      "Loan Repayment                       0.962963  1.000000  0.981132     52.0\n",
      "Mandatory Prepayments / Redemption   1.000000  1.000000  1.000000     49.0\n",
      "NA                                   1.000000  0.962376  0.980827   1515.0\n",
      "Optional Prepayment / Redemption     0.800000  1.000000  0.888889     12.0\n",
      "Permitted Indebtedness               1.000000  0.968750  0.984127     32.0\n",
      "Premium and Fees                     1.000000  1.000000  1.000000     49.0\n",
      "Prepayment                           0.973684  1.000000  0.986667     37.0\n",
      "Reporting Requirements               0.950820  0.950820  0.950820     61.0\n",
      "Restricted Investments               0.928571  1.000000  0.962963     13.0\n",
      "Restricted Payments                  0.870968  0.964286  0.915254     28.0\n",
      "Transactions with Affiliates         0.967742  1.000000  0.983607     30.0\n",
      "Waterfall of Proceeds                0.869565  1.000000  0.930233     40.0\n",
      "macro avg                            0.934878  0.993314  0.962139   2468.0\n",
      "weighted avg                         0.977250  0.974878  0.975300   2468.0\n"
     ]
    }
   ],
   "source": [
    "print(fold_df.groupby('tag').agg('mean').to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b834fa43-41bb-4055-8387-2debcd29e93c",
   "metadata": {},
   "source": [
    "## Generate Results on Unsampled NA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79155d24-f0e9-4b85-898d-65c626e35c08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seen_df = pd.read_json(\"./data/cleaned_tags_data.json\")\n",
    "all_df = pd.read_json(\"./data/all-data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cf7e89-9050-4b6e-b588-da7e3e27f1e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unseen_df = all_df.merge(seen_df, how='left', on=['filename', 'tags', 'title', 'category', 'word_count', 'section_content'], indicator=True, )\n",
    "unseen_df = unseen_df[unseen_df['_merge'] == 'left_only']\n",
    "unseen_df = unseen_df.drop(columns=['_merge'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9532b7f8-ba2e-4f4c-b30b-a297f9496021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "unseen_df['tags'] = unseen_df['tags'].str.replace(\"Events of Default\", \"Event of Default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9fcc85-b1c8-4ac7-b726-c897d1a70b8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unseen_texts = unseen_df['section_content'].values\n",
    "unseen_labels = unseen_df['tags'].values\n",
    "unseen_labels = label_encoder.transform(unseen_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300a27ee-844a-4883-80f2-edd744ce59da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unseen_dataset = TextDataset(unseen_texts, unseen_labels, tokenizer, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff28a86-4987-48d2-8d7f-f2bec7170ed2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = trainer.predict(unseen_dataset)\n",
    "\n",
    "# Extract the logits and convert to predicted labels\n",
    "logits = predictions.predictions\n",
    "predicted_labels = np.argmax(logits, axis=-1)\n",
    "\n",
    "# Convert numeric labels back to original text labels for comparison\n",
    "predicted_labels_text = label_encoder.inverse_transform(predicted_labels)\n",
    "true_labels_text = label_encoder.inverse_transform(unseen_labels)\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(true_labels_text, predicted_labels_text, target_names=label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e56f6df-0794-42cb-98fa-5dc4136c9c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4374cd9-18d1-4374-b4b1-1171a387a214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a60909-9c19-4e80-b657-65ae01442403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_df = pd.read_json(\"./data/all-data.json\")\n",
    "print(all_df.shape)\n",
    "all_df = all_df[all_df.word_count > 20]\n",
    "print(all_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5362c67f-3a91-4011-9e98-9274afc18178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2f6f60-04dc-41a8-8096-e2891d12e019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7240c4e5-3acb-4176-a8de-a09e9e98197a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df['predicted_tags'] = predicted_labels_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133053cb-d347-426f-9ec5-f364beb2fbdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0534d6c-cb0a-4932-b35b-8320c1a63c28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_df = all_df[['section_content', 'tags']].groupby('section_content').agg(list).reset_index()\n",
    "group_df['n_tags'] = group_df.tags.apply(lambda x: len(x))\n",
    "group_df['n_unique_tags'] = group_df.tags.apply(lambda x: len(set(x)))\n",
    "print(group_df[group_df.n_tags > 1].shape)\n",
    "print(group_df[group_df.n_unique_tags > 1].shape)\n",
    "group_df.sort_values(by='n_unique_tags', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38bb147-4b79-40a4-a043-bf48ebd03863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527e563a-72fc-4ed8-9bf5-dadf9a41cdd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df[[\"section_content\", \"predicted_tags\"]].merge(all_df.drop_duplicates(\"section_content\"), how=\"left\", on=\"section_content\", validate=\"one_to_one\").to_excel(\"./data/output/test_data_predictions.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11211d80-d757-4a9d-92d3-9292644ba218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d48248-8dd6-4b5e-892a-8f6c86535fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c491b-9b0f-4b6d-8e16-c3519c5b3cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_labels(texts, model, tokenizer, label_encoder, max_length=512, device='cuda'):\n",
    "    # Move model to the specified device\n",
    "    model.to(device)\n",
    "    \n",
    "    # Tokenize the texts\n",
    "    encodings = tokenizer(\n",
    "        texts,\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Move tensors to the same device as the model\n",
    "    input_ids = encodings['input_ids'].to(device)\n",
    "    attention_mask = encodings['attention_mask'].to(device)\n",
    "    \n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Perform the inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    # Move predictions back to the CPU before converting to numpy\n",
    "    predicted_labels = label_encoder.inverse_transform(predictions.cpu().numpy())\n",
    "    \n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b037728-c863-4e9b-ba48-d7aafeca33aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_labels_text = predict_labels(test_texts.tolist(), model, tokenizer, label_encoder)\n",
    "true_labels_text = label_encoder.inverse_transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a924cab-231b-4ecc-8869-3f69b492374e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ebe6a-4610-49bc-b085-7168ff4b2a6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the logits and convert to predicted labels\n",
    "# logits = predictions.predictions\n",
    "# predicted_labels = np.argmax(logits, axis=-1)\n",
    "\n",
    "# Convert numeric labels back to original text labels for comparison\n",
    "# Generate a classification report\n",
    "report = classification_report(true_labels_text, predicted_labels_text, target_names=label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af914524-1988-4f1f-9c94-47aa47e3ec47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.0 Python 3.10 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-2.0.0-gpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
